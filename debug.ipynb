{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/diffusers/models/dual_transformer_2d.py:20: FutureWarning: `DualTransformer2DModel` is deprecated and will be removed in version 0.29. Importing `DualTransformer2DModel` from `diffusers.models.dual_transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.transformers.dual_transformer_2d import DualTransformer2DModel`, instead.\n",
      "  deprecate(\"DualTransformer2DModel\", \"0.29\", deprecation_message)\n"
     ]
    }
   ],
   "source": [
    "from sdup.pipelines.pipeline_stablediffusionupscale import StableVideoDiffusionUpscalePipeline\n",
    "from sdup.models.unet import UNet3DConditionModel\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from decord import VideoReader\n",
    "\n",
    "from diffusers.utils import export_to_gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing_keys: <All keys matched successfully>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f593ed0686b940dfab246696cc67eb1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/qiguojun/PreTrainedWeights/stable-diffusion-x4-upscaler/text_encoder/model.safetensors\n",
      "/qiguojun/PreTrainedWeights/stable-diffusion-x4-upscaler/text_encoder/model.safetensors\n"
     ]
    }
   ],
   "source": [
    "pipe_path = '/qiguojun/PreTrainedWeights/stable-diffusion-x4-upscaler'\n",
    "unet = UNet3DConditionModel.from_pretrained_2d(pipe_path, subfolder='unet')\n",
    "pipe = StableVideoDiffusionUpscalePipeline.from_pretrained(pipe_path, unet=unet).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9b66ff790d2479b90c88bce268a45bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "src_img = Image.open('./asset/sora.jpg').resize((128, 128))\n",
    "prompt = 'a photo of five monster'\n",
    "\n",
    "up_img = pipe(image=[src_img], prompt=prompt, num_inference_steps=25).images[0]\n",
    "src_img.save('./src_img.jpg')\n",
    "up_img.save('./up_img.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "835c75bd7da44412a18b37152068a7e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'./up_video.gif'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid_path = './asset/real01_inp.mp4'\n",
    "frames_source = 8 # input video frames\n",
    "video_reader = VideoReader(vid_path)\n",
    "_, h, w, _ = video_reader.get_batch([0]).shape\n",
    "video_ = video_reader.get_batch(range(len(video_reader))).asnumpy()[:frames_source]\n",
    "video = []\n",
    "for vid in video_:\n",
    "    video.append(Image.fromarray(vid).resize((w//8, h//8)))\n",
    "h = h//8; w = w//8\n",
    "prompt='a photo of giraffes graze in the bushes'\n",
    "\n",
    "video_up = pipe(prompt=prompt, image=video, num_inference_steps=25).images\n",
    "export_to_gif(video, './src_video.gif')\n",
    "export_to_gif(video_up, './up_video.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
